{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afe13d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from typing import Tuple, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from mordred import Calculator, descriptors\n",
    "#import openbabel\n",
    "from openbabel import pybel\n",
    "from PyBioMed.PyMolecule.fingerprint import CalculatePubChemFingerprint,CalculateECFP2Fingerprint\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.rdchem import Atom\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader as G_Loader \n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, matthews_corrcoef, roc_curve, auc \n",
    "from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ab1d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fingerprint_features(smiles_list: List[str]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute ECFP2 & PubChem fingerprint features for a list \n",
    "    of SMILES strings\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    smiles_list: List[str]\n",
    "        The list of SMILES strings.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Returns a 2D numpy array, where each row corrsponds\n",
    "        to the fingerprints of a SMILES strings in order.\n",
    "    \"\"\"\n",
    "    molecular_mols = [Chem.MolFromSmiles(smi) for smi in smiles_list]\n",
    "    # Initialize an array to store ECFP2 & PubChem fingerprint features\n",
    "    features = np.zeros((len(smiles_list), 1024 + 881), dtype=np.int32)\n",
    "\n",
    "    for i, mol in enumerate(molecular_mols):\n",
    "        ECFP2_mol_fingerprint = CalculateECFP2Fingerprint(mol)\n",
    "        pubchem_mol_fingerprint = CalculatePubChemFingerprint(mol)\n",
    "        numerical_representation = np.concatenate(\n",
    "            (ECFP2_mol_fingerprint[0], pubchem_mol_fingerprint))\n",
    "        features[i] = numerical_representation\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def compute_descriptor_features(smiles_list: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute 2D descriptor features for a list of SMILES strings\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    smiles_list: List[str]\n",
    "        The list of SMILES strings.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Returns a pandas dataframe, where each row corrsponds\n",
    "        to the descriptors of a SMILES strings in order.\n",
    "    \"\"\"\n",
    "    descriptor_calc_2D = Calculator(descriptors, ignore_3D=True)\n",
    "    molecular_mols = [Chem.MolFromSmiles(smi) for smi in smiles_list]\n",
    "    descriptors_2D = descriptor_calc_2D.pandas(molecular_mols)\n",
    "    return descriptors_2D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9442733",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./graph_feature.ipynb \n",
    "%run ./dataset_processing.ipynb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f201063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET ALL DATA \n",
    "pd_smiles,pd_labels = get_dataset('all_dataset_mtbpen5371.csv')\n",
    "\n",
    "# SPLIT DATA TRAIN AND TEST 90 AND 10 \n",
    "X_train, X_test, y_train, y_test = train_test_split(pd_smiles, pd_labels, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0056c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_smiles_train = X_train\n",
    "pd_smiles_test = X_test\n",
    "pd_labels_train = y_train\n",
    "pd_labels_test = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357e4cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_y_smiles                   = list(pd_labels_train)\n",
    "list_y_smiles_test              = list(pd_labels_test)\n",
    "list_X_smiles                   = list(pd_smiles_train) \n",
    "list_X_smiles_test              = list(pd_smiles_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadb35d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHUFFLE FROM THE BEGINNInG \n",
    "# SHUFFLE TO SPREAD THE DATA WITH LABEL 0 AND 1 RANDOMLY AND CREATE K-FOLD CROSSVALIDATION\n",
    "# ========================================================================================\n",
    "k                               = 10\n",
    "X_1,y_1                         = shuffle(list_X_smiles, list_y_smiles)\n",
    "train_data                      = X_1\n",
    "train_targets                   = y_1\n",
    "all_train_indices, all_val_indices, total_train_data,total_train_targets,total_validation_data,total_validation_targets = CF_Validation_version_2(k,train_data,train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5accdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save all the index \n",
    "# train, validation, and test \n",
    "np.save('train_indices.npy', all_train_indices)\n",
    "np.save('val_indices.npy', all_val_indices)\n",
    "np.save('test_indices.npy', len(list_X_smiles_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5967bdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONVERT TO VEC DATA FROM SMILES AFTER CROSS FOLD VALIDATION \n",
    "def convert2vec(input_data_smiles):\n",
    "    fingerprints = compute_fingerprint_features(input_data_smiles)\n",
    "    descriptors = compute_descriptor_features(input_data_smiles)\n",
    "    return descriptors, fingerprints\n",
    "\n",
    "# convert the total train , validation, and test into vector data\n",
    "def convert2vec_group(total_data):\n",
    "    data_vec = [] # this would be 5 x 2 matriks \n",
    "    for one_fold in total_data:\n",
    "        data_vec.append(convert2vec(one_fold))\n",
    "                        \n",
    "    return data_vec\n",
    "                                                              # fold x numberdata x number features(2 x 1) descriptor and fing                \n",
    "data_vec_train  = convert2vec_group(total_train_data)         #(5 x 2330 x number features)\n",
    "data_vec_val    = convert2vec_group(total_validation_data)\n",
    "data_vec_test   = convert2vec(list_X_smiles_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b45765a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numbers\n",
    "def coerce_to_numeric(value):\n",
    "    if isinstance(value, numbers.Number):\n",
    "        return value\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Returns a cleaned version of df[col1]\n",
    "#clean_col = df[col1].apply(coerce_to_numeric)\n",
    "#for data in descriptors_train.loc[0]:\n",
    "#    print(coerce_to_numeric(data))\n",
    "\n",
    "# input is list of descriptors and change it into data list\n",
    "def find_notnumber_n_replace(descriptors):\n",
    "    list_data= []\n",
    "    for j in range(len(descriptors)):\n",
    "        one_feature=[]\n",
    "        for data in descriptors.loc[j]:\n",
    "            clean_data = coerce_to_numeric(data)\n",
    "            one_feature.append(clean_data)\n",
    "        list_data.append(one_feature)\n",
    "    return list_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdaaa75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REPAIR ALL DATA\n",
    "def repair_data(total_vec_data):\n",
    "    total_data_vec=[]\n",
    "    if len(total_vec_data)>2 :\n",
    "        for data in total_vec_data:\n",
    "            descriptors = data[0]\n",
    "            fingerprints = data[1]\n",
    "            list_data = find_notnumber_n_replace(descriptors)\n",
    "            total_data_vec.append([list_data, fingerprints])\n",
    "    else :\n",
    "        descriptors = total_vec_data[0]\n",
    "        fingerprints = total_vec_data[1]\n",
    "        list_data = find_notnumber_n_replace(descriptors)\n",
    "        total_data_vec.append([list_data, fingerprints])\n",
    "    \n",
    "    return total_data_vec\n",
    "\n",
    "#descriptors = data_vec_train[0][0] # descriptor in fold 0\n",
    "#list_data = find_notnumber_n_replace(descriptors)\n",
    "\n",
    "data_vec_train1 = repair_data(data_vec_train)\n",
    "data_vec_val1   = repair_data(data_vec_val)\n",
    "data_vec_test1  = repair_data(data_vec_test)\n",
    "#data_vec_val1   = repair_data(data_vec_val)\n",
    "#data_vec_test1  = repair_data(data_vec_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c43c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cek_null(descriptors):\n",
    "    count_isnull =0\n",
    "    name_isnull_label=[]\n",
    "    for i in range(len(descriptors.isnull().sum())): \n",
    "        if descriptors.isnull().sum().iloc[i] > 0:\n",
    "            count_isnull = count_isnull+1 \n",
    "            name_isnull_label.append(descriptors.isnull().sum().index[i])\n",
    "    return count_isnull, name_isnull_label\n",
    "\n",
    "# just cek only once \n",
    "count_isnull, name_isnull_label = cek_null(data_vec_train[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d16b030",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_isnull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1368e4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_isnull_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842a7c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_isnull_val, name_isnull_label_val = cek_null(data_vec_val[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba260f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_isnull_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b51506",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_isnull_label_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12eed73",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_isnull_test, name_isnull_label_test = cek_null(data_vec_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762a7eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_isnull_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cf57c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_isnull_label_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bb27ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cek_null_fingerprints(fingerprints):\n",
    "    get_idx = []\n",
    "    get_row =[]\n",
    "    for row,_ in enumerate(fingerprints):\n",
    "        for idx, data in enumerate(fingerprints[row]):\n",
    "            if data != 0 and data !=1:\n",
    "                get_idx.append(idx)\n",
    "                get_row.append(row)\n",
    "    return get_idx, get_row\n",
    "\n",
    "get_idx_train, get_row_train = cek_null_fingerprints(data_vec_train[0][1])\n",
    "get_idx_val, get_row_val = cek_null_fingerprints(data_vec_val[0][1])\n",
    "get_idx_test, get_row_test = cek_null_fingerprints(data_vec_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad55de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_idx_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e008f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_row_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75802401",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_idx_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9338e0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_idx_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b7411a",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_idx_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40852584",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_row_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc13bd3d",
   "metadata": {},
   "source": [
    "# 1.  feature selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d77650b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use standardized descriptor \n",
    "# i think the normalized data is too small \n",
    "# combine first fingerprints and descriptor \n",
    "from sklearn.feature_selection import VarianceThreshold,chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d03e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_train =[]\n",
    "fingerp_train =[]\n",
    "for desc, fingerp in data_vec_train1:\n",
    "    desc_train.append(desc)\n",
    "    fingerp_train.append(fingerp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db47034d",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_val =[]\n",
    "fingerp_val =[]\n",
    "for desc, fingerp in data_vec_val1:\n",
    "    desc_val.append(desc)\n",
    "    fingerp_val.append(fingerp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95127ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_test = data_vec_test1[0][0]\n",
    "fingerp_test = data_vec_test1[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e07943",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(desc_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2496d5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose just only one fold for fitting the variance threshold\n",
    "total_desc       = desc_train[0] + desc_val[0]\n",
    "total_fingerp    = np.concatenate ((fingerp_train[0], fingerp_val[0]), axis= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4989ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(total_desc) # total number of data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8312e7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature number before selection \n",
    "print(len(total_desc[0])) \n",
    "print(len(total_fingerp[0])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245b0fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll get bad feature from variance threshold and chi2\n",
    "variance_desc =VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
    "variance_fingerp =VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
    "pd_desc = pd.DataFrame(total_desc)\n",
    "pd_fingerp = pd.DataFrame(total_fingerp)\n",
    "\n",
    "result_desc = variance_desc.fit(pd_desc)\n",
    "result_fingerp = variance_fingerp.fit(pd_fingerp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403d9f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_desc_train =[]\n",
    "group_fingerp_train=[]\n",
    "for desc,fingerp in zip (desc_train, fingerp_train):\n",
    "    group_desc_train.append(result_desc.transform(desc))\n",
    "    group_fingerp_train.append(result_fingerp.transform(fingerp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072a371b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(group_desc_train[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0148411",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(group_fingerp_train[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8471381",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_name = variance_desc.get_feature_names_out()\n",
    "len(desc_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f329add",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac3797b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(group_fingerp_train[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7517ec17",
   "metadata": {},
   "outputs": [],
   "source": [
    "fingerp_name = variance_fingerp.get_feature_names_out()\n",
    "len(fingerp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac936a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fingerp_name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ab8329",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_desc_val =[]\n",
    "group_fingerp_val=[]\n",
    "for desc,fingerp in zip (desc_val, fingerp_val):\n",
    "    group_desc_val.append(result_desc.transform(desc))\n",
    "    group_fingerp_val.append(result_fingerp.transform(fingerp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c8c1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_desc_test = result_desc.transform(desc_test)\n",
    "group_fingerp_test = result_fingerp.transform(fingerp_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d02dfb",
   "metadata": {},
   "source": [
    "# 2. max-min scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d578e8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, Normalizer, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# scale only descriptor \n",
    "# chi square test need positive data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b941f9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizer = Normalizer()\n",
    "Scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af25707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join only the descriptor \n",
    "filtered_desc_train = np.concatenate((group_desc_train[0],group_desc_val[0]),axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3366bac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler1       = Scaler.fit(filtered_desc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4726532e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_desc_train=[]\n",
    "scaled_desc_val=[]\n",
    "for data_train,data_val in zip (group_desc_train, group_desc_val): \n",
    "    scaled_desc_train.append(scaler1.transform(data_train))\n",
    "    scaled_desc_val.append(scaler1.transform(data_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe63dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_desc_test = scaler1.transform(group_desc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418c1613",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_desc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3726ac95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we have these data \n",
    "#FINGERPRINTS\n",
    "# group_fingerp_train\n",
    "# group_fingerp_val\n",
    "# group_fingerp_test\n",
    "\n",
    "#SCALED DESCRIPTORS\n",
    "# and \n",
    "# scaled_desc_train\n",
    "# scaled_desc_val\n",
    "# scaled_desc_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebaaf0d",
   "metadata": {},
   "source": [
    "# 3. chi- squared test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4579ff43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data descriptor and fingerprints\n",
    "np_desc_train = np.concatenate((scaled_desc_train[0],scaled_desc_val[0]),axis= 0)\n",
    "np_fingerp_train = np.concatenate((group_fingerp_train[0],group_fingerp_val[0]),axis= 0)\n",
    "\n",
    "np_label =np.concatenate((total_train_targets[0],total_validation_targets[0]),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338902ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(np_desc_train))\n",
    "print(len(np_fingerp_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193fd401",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84da46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_score_desc = chi2(np_desc_train,np_label)\n",
    "f_score_fingerp = chi2(np_fingerp_train,np_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088cf210",
   "metadata": {},
   "outputs": [],
   "source": [
    "pValue_desc = pd.Series(f_score_desc[1])\n",
    "pValue_fingerp = pd.Series(f_score_fingerp[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c79858",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_sort_desc = pValue_desc.sort_values(ascending=False)\n",
    "pd_sort_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db20a40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_sort_fingerp = pValue_fingerp.sort_values(ascending=False)\n",
    "pd_sort_fingerp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471dab91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bad_features(pValue,thr):\n",
    "    list_bad_feature=[]\n",
    "    for i in range(len(pValue)):\n",
    "        if pValue[i] < thr:\n",
    "            list_bad_feature.append(i)\n",
    "    return list_bad_feature\n",
    "\n",
    "thr1 = 0.7\n",
    "thr2 = 0.5\n",
    "list_bad_feature_chi_desc = get_bad_features(pValue_desc,thr1)\n",
    "list_bad_feature_chi_fingerp = get_bad_features(pValue_fingerp,thr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144d222d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(list_bad_feature_chi_desc))\n",
    "print(len(list_bad_feature_chi_fingerp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0d363f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_clean_desc_train = []\n",
    "final_clean_desc_val = []\n",
    "final_clean_desc_test = []\n",
    "\n",
    "final_clean_fingerp_train = []\n",
    "final_clean_fingerp_val = []\n",
    "final_clean_fingerp_test = []\n",
    "\n",
    "for data_train, data_val in zip(scaled_desc_train, scaled_desc_val):\n",
    "    final_clean_desc_train.append(np.delete(data_train, list_bad_feature_chi_desc, axis=1))\n",
    "    final_clean_desc_val.append(np.delete(data_val, list_bad_feature_chi_desc, axis=1))\n",
    "\n",
    "final_clean_desc_test = np.delete(scaled_desc_test, list_bad_feature_chi_desc, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb6c7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_train, data_val in zip(group_fingerp_train, group_fingerp_val):\n",
    "    final_clean_fingerp_train.append(np.delete(data_train, list_bad_feature_chi_fingerp, axis=1))\n",
    "    final_clean_fingerp_val.append(np.delete(data_val, list_bad_feature_chi_fingerp, axis=1))\n",
    "\n",
    "final_clean_fingerp_test = np.delete(group_fingerp_test, list_bad_feature_chi_fingerp, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130bd8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(final_clean_desc_train[0][0]))\n",
    "print(len(final_clean_desc_val[0][0]))\n",
    "print(len(final_clean_desc_test[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273b8220",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(final_clean_fingerp_train[0][0]))\n",
    "print(len(final_clean_fingerp_val[0][0]))\n",
    "print(len(final_clean_fingerp_test[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eadd4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_clean_desc_train[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7a7044",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_clean_desc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c52ae8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_clean_fingerp_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9aa282f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data vector (use variance threshold and chi squared)\n",
    "# data for descriptor\n",
    "# this is saved in numpy data \n",
    "np.save('final_clean_desc_train0.npy',final_clean_desc_train[0])\n",
    "np.save('final_clean_desc_train1.npy',final_clean_desc_train[1])\n",
    "np.save('final_clean_desc_train2.npy',final_clean_desc_train[2])\n",
    "np.save('final_clean_desc_train3.npy',final_clean_desc_train[3])\n",
    "np.save('final_clean_desc_train4.npy',final_clean_desc_train[4])\n",
    "np.save('final_clean_desc_train5.npy',final_clean_desc_train[5])\n",
    "np.save('final_clean_desc_train6.npy',final_clean_desc_train[6])\n",
    "np.save('final_clean_desc_train7.npy',final_clean_desc_train[7])\n",
    "np.save('final_clean_desc_train8.npy',final_clean_desc_train[8])\n",
    "np.save('final_clean_desc_train9.npy',final_clean_desc_train[9])\n",
    "# save the data vector \n",
    "# this is saved in numpy data \n",
    "np.save('final_clean_desc_val0.npy',final_clean_desc_val[0])\n",
    "np.save('final_clean_desc_val1.npy',final_clean_desc_val[1])\n",
    "np.save('final_clean_desc_val2.npy',final_clean_desc_val[2])\n",
    "np.save('final_clean_desc_val3.npy',final_clean_desc_val[3])\n",
    "np.save('final_clean_desc_val4.npy',final_clean_desc_val[4])\n",
    "np.save('final_clean_desc_val5.npy',final_clean_desc_val[5])\n",
    "np.save('final_clean_desc_val6.npy',final_clean_desc_val[6])\n",
    "np.save('final_clean_desc_val7.npy',final_clean_desc_val[7])\n",
    "np.save('final_clean_desc_val8.npy',final_clean_desc_val[8])\n",
    "np.save('final_clean_desc_val9.npy',final_clean_desc_val[9])\n",
    "\n",
    "np.save('final_clean_desc_test.npy',final_clean_desc_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf43ecd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data for fingerprint\n",
    "np.save('final_clean_fingerp_train0.npy',final_clean_fingerp_train[0])\n",
    "np.save('final_clean_fingerp_train1.npy',final_clean_fingerp_train[1])\n",
    "np.save('final_clean_fingerp_train2.npy',final_clean_fingerp_train[2])\n",
    "np.save('final_clean_fingerp_train3.npy',final_clean_fingerp_train[3])\n",
    "np.save('final_clean_fingerp_train4.npy',final_clean_fingerp_train[4])\n",
    "np.save('final_clean_fingerp_train5.npy',final_clean_fingerp_train[5])\n",
    "np.save('final_clean_fingerp_train6.npy',final_clean_fingerp_train[6])\n",
    "np.save('final_clean_fingerp_train7.npy',final_clean_fingerp_train[7])\n",
    "np.save('final_clean_fingerp_train8.npy',final_clean_fingerp_train[8])\n",
    "np.save('final_clean_fingerp_train9.npy',final_clean_fingerp_train[9])\n",
    "\n",
    "# save the data vector \n",
    "# this is saved in numpy data \n",
    "np.save('final_clean_fingerp_val0.npy',final_clean_fingerp_val[0])\n",
    "np.save('final_clean_fingerp_val1.npy',final_clean_fingerp_val[1])\n",
    "np.save('final_clean_fingerp_val2.npy',final_clean_fingerp_val[2])\n",
    "np.save('final_clean_fingerp_val3.npy',final_clean_fingerp_val[3])\n",
    "np.save('final_clean_fingerp_val4.npy',final_clean_fingerp_val[4])\n",
    "np.save('final_clean_fingerp_val5.npy',final_clean_fingerp_val[5])\n",
    "np.save('final_clean_fingerp_val6.npy',final_clean_fingerp_val[6])\n",
    "np.save('final_clean_fingerp_val7.npy',final_clean_fingerp_val[7])\n",
    "np.save('final_clean_fingerp_val8.npy',final_clean_fingerp_val[8])\n",
    "np.save('final_clean_fingerp_val9.npy',final_clean_fingerp_val[9])\n",
    "\n",
    "np.save('final_clean_fingerp_test.npy',final_clean_fingerp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58936aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_test_targets = np.array(list_y_smiles_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfc534e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the label also \n",
    "# save the data vector (only use variance threshold)\n",
    "# this is saved in numpy data \n",
    "np.save('total_train_targets0.npy',total_train_targets[0])\n",
    "np.save('total_train_targets1.npy',total_train_targets[1])\n",
    "np.save('total_train_targets2.npy',total_train_targets[2])\n",
    "np.save('total_train_targets3.npy',total_train_targets[3])\n",
    "np.save('total_train_targets4.npy',total_train_targets[4])\n",
    "np.save('total_train_targets5.npy',total_train_targets[5])\n",
    "np.save('total_train_targets6.npy',total_train_targets[6])\n",
    "np.save('total_train_targets7.npy',total_train_targets[7])\n",
    "np.save('total_train_targets8.npy',total_train_targets[8])\n",
    "np.save('total_train_targets9.npy',total_train_targets[9])\n",
    "\n",
    "# save the data vector \n",
    "# this is saved in numpy data \n",
    "np.save('total_validation_targets0.npy',total_validation_targets[0])\n",
    "np.save('total_validation_targets1.npy',total_validation_targets[1])\n",
    "np.save('total_validation_targets2.npy',total_validation_targets[2])\n",
    "np.save('total_validation_targets3.npy',total_validation_targets[3])\n",
    "np.save('total_validation_targets4.npy',total_validation_targets[4])\n",
    "np.save('total_validation_targets5.npy',total_validation_targets[5])\n",
    "np.save('total_validation_targets6.npy',total_validation_targets[6])\n",
    "np.save('total_validation_targets7.npy',total_validation_targets[7])\n",
    "np.save('total_validation_targets8.npy',total_validation_targets[8])\n",
    "np.save('total_validation_targets9.npy',total_validation_targets[9])\n",
    "\n",
    "np.save('total_test_targets.npy',total_test_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a38cbc",
   "metadata": {},
   "source": [
    "# graph data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b71cd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RDkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.rdmolops import GetAdjacencyMatrix\n",
    "# Pytorch and Pytorch Geometric\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.nn import Linear\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F # activation function\n",
    "from torch.utils.data import Dataset, DataLoader # dataset management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2193df7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONVERT THE DATASET INTO GRAPH STRUCTURED DATA \n",
    "# BOTH DATA_TRAIN AND DATA_VALIDATION ARE PREPARED IN GRAPH STRUCTURED DATA \n",
    "#=============================================================================================\n",
    "data_list_train = []\n",
    "data_list_val =[]\n",
    "for X_train,y_train,X_val,y_val in zip(total_train_data, total_train_targets, total_validation_data, total_validation_targets):\n",
    "    data_graph_train = create_pytorch_geometric_graph_data_list_from_smiles_and_labels(X_train, y_train)\n",
    "    data_graph_val   = create_pytorch_geometric_graph_data_list_from_smiles_and_labels(X_val, y_val)\n",
    "    \n",
    "    data_list_train.append(data_graph_train)\n",
    "    data_list_val.append(data_graph_val)\n",
    "\n",
    "    \n",
    "# INDEPENDENT DATASET IN GRAPH STRUCTURED DATA\n",
    "#===========================================================================================\n",
    "x_smiles = list_X_smiles_test\n",
    "y = list_y_smiles_test\n",
    "\n",
    "data_list_test = create_pytorch_geometric_graph_data_list_from_smiles_and_labels(x_smiles, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044bdc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14659c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb23f4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    path = './data_train_' + str(i)\n",
    "    # create new single directory\n",
    "    os.mkdir(path)\n",
    "    for idx, tensor in enumerate(data_list_train[i]):\n",
    "        torch.save(tensor, f\"data_train_{i}/tensor{idx}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9489a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    path = './data_val_' + str(i)\n",
    "    # create new single directory\n",
    "    os.mkdir(path)\n",
    "    for idx, tensor in enumerate(data_list_val[i]):\n",
    "        torch.save(tensor, f\"data_val_{i}/tensor{idx}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec02d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './data_test' \n",
    "# create new single directory\n",
    "os.mkdir(path)\n",
    "for idx, tensor in enumerate(data_list_test):\n",
    "    torch.save(tensor, f\"data_test/tensor{idx}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1d693f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
